			+--------------------+
			|        CS 153      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

Calvin Huynn <chuyn006@ucr.edu> <861015448>
Jeffrey Chen <jchen086@ucr.edu> <861021330>
Derrick Lam <dlam012@ucr.edu> <861005721>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

The goal of timer_sleep() is to stop executing the current thread 
for x-number of ticks. We place the thread onto a list of blocked 
threads. After a set amount of ticks, the thread is unblocked and
then placed on a ready list. This implementation may have a slight
delay due to the latency present when blocking, unblocking, and then
waiting for the thread to resume running. However, it is far better 
than the provided timer_sleep() function, because the provided 
implementation stayed in a while loop, constantly calling
thread_yield() until the current number of ticks exceeded the 
required amount of ticks.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The interrupt handler interrupts every tick to increment the tick
counter. It will also check the blocked threads in the blocked thread
list and unblock them if their sleep duration is over. By sorting the 
blocked thread list by lowest remaining sleep time, we only need to
check the first element in the list to determine if we need to unblock
any threads at all. 

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Using the list structure allows the threads to be kept in an orderly
fashion. When a thread is added to the blocked list, interrupts will disabled
so that there will be no conflicts or other issues. By utilizing assert
statements, it can be made absolutely certain that the interrupts are
disabled during this critical section.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Interrupts will be disabled during the critical section when a thread
is added to the blocked list. This has a side effect of delaying any
possible unblocking done during the interrupt, but hopefully it will
be a negligable amount of delay. 

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose to minimize the interupt times through the implementation of a 
wait and ready list. Blocking threads avoid waiting for ticks if we had 
still implemented thread_yield(). The implementation of a sorted list of
objects avoids waiting conflicts while minimizing time spent looking for
a thread to unblock.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

int donated_priority
	Included in thread.h to ensure that the priority variable is not overwritten
	when the thread is donated to. 

thread_set_priority()
	Changed to include locks to avoid possible race conditions when setting
	priority happens at the same time a lock is removed. 
thread_get_priority()
	The higher value between priority and donated_priority is returned

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

A thread on the waiting list will donate it's priority to a thread on 
the ready list that it is waiting on to run first.

==========Before==========
Ready List    Waiting list
P2 [mid]      P3 [high]-
                       |
P1 [low]<---------------

==========After===========
Ready List    Waiting list
P1 [high]<--  P3 [high]
            |____|  
P2 [mid]

In this example, P2 is initially the thread with the highest priority,
and as a result, is next to begin running. However, due to P3 waiting on
P1, and P3 having a high priority, P1's priority is upgraded to what P3's is,
and the order in the ready list is updated to reflect this.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We make sure that when the threads are added to the priority list,
we need to order the list from highest to lowest priority. That way, 
we make sure that the thread with the highest priority wakes up first.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When a thread calls lock_acquire(), any other threads dependent on the
main thread that have a higher priority than the locked thread will 
allocate a temporary priority to the locked thread to have the locked
thread unlock faster so that the dependent thread can run. In the case
of a nested donation, the highest priority dependent thread will propogate
its high priority value upward to allow the lock thread to process at
an expedited priority and unlock faster.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When lock_release() is called, the locked thread and all of it's dependents
regain their initial priority. From there, the list of threads will then be
sorted based upon these new priorities, placing the higher-priority thread
higher up in the ready queue.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

There is a possibility for a race condition when calling thread_set_priority()
during the period when a thread is the process of restoring its own priority
when any donated priority from a locked thread is released. The inverse needs to
be handled as well, because if the thread's priority is increased, any donation
must be based on this new priority. The type of lock that needs to be used has to be 
on a thread-by-thread basis.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

Another considered design is to 
			  ADVANCED SCHEDULER
			    (If Attempted)
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
